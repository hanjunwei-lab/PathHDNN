{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pretrain GCNs...\n",
      "\n",
      "Training...\n",
      "\n",
      "Test: Epoch 0\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.583\n",
      "\n",
      "\n",
      "Test: Epoch 50\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 100\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 150\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 200\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 250\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 300\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 350\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 400\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 450\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 500\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 550\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 600\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 650\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 700\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 750\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 800\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 850\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 900\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 950\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1000\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1050\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1100\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1150\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1200\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1250\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1300\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1350\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1400\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1450\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1500\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1550\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1600\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1650\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1700\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1750\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1800\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1850\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1900\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 1950\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2000\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2050\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2100\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2150\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2200\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2250\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2300\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2350\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2400\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2450\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "\n",
      "Test: Epoch 2500\n",
      "Test ACC: 0.750\n",
      "Test F1: 0.000\n",
      "Test AUC: 0.250\n",
      "\n",
      "最终预测结果已保存到 data(li)delete10\\final_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example for MOGONET classification\n",
    "\"\"\"\n",
    "from train_test import train_test\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    data_folder ='data(li)delete10//训练'\n",
    "    view_list = [1,2,3]\n",
    "    num_epoch_pretrain = 500\n",
    "    num_epoch = 2500\n",
    "    lr_e_pretrain = 1e-3\n",
    "    lr_e = 5e-4\n",
    "    lr_c = 1e-3\n",
    "    \n",
    "    if data_folder == 'ROSMAP':\n",
    "        num_class = 2\n",
    "    if data_folder == 'data(li)delete10//训练':\n",
    "        num_class = 2\n",
    "    \n",
    "    train_test(data_folder, view_list, num_class,\n",
    "               lr_e_pretrain, lr_e, lr_c, \n",
    "               num_epoch_pretrain, num_epoch)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###外部验证\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, average_precision_score, precision_score\n",
    "from utils import gen_adj_mat_tensor, cal_adj_mat_parameter  # 确保导入你需要的函数\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "def load_model(model_save_path):\n",
    "    # 加载最佳模型\n",
    "    model_dict = torch.load(os.path.join(model_save_path, 'trained_model.model'))\n",
    "    return model_dict\n",
    "\n",
    "def preprocess_external_data(data_folder, view_list):\n",
    "    # 读取外部验证集数据\n",
    "    labels_ext = pd.read_csv(os.path.join(data_folder, \"labels_ext.csv\")).values\n",
    "#    labels_ext = np.loadtxt(os.path.join(data_folder, \"labels_ext.csv\"), delimiter=',')\n",
    "    labels_ext = labels_ext.astype(int)\n",
    "    data_ext_list = []\n",
    "    for i in view_list:\n",
    "        data_ext_list.append(np.loadtxt(os.path.join(data_folder, f\"{i}_ext.csv\"), delimiter=','))\n",
    "    \n",
    "    data_tensor_list = []\n",
    "    for i in range(len(data_ext_list)):\n",
    "        data_tensor_list.append(torch.FloatTensor(data_ext_list[i]))\n",
    "        if cuda:\n",
    "            data_tensor_list[i] = data_tensor_list[i].cuda()\n",
    "    \n",
    "    return data_tensor_list, labels_ext\n",
    "\n",
    "def generate_adj_matrix(data_ext_list, adj_parameter):\n",
    "    adj_metric = \"cosine\"  # cosine distance\n",
    "    adj_ext_list = []\n",
    "    for i in range(len(data_ext_list)):\n",
    "        adj_parameter_adaptive = cal_adj_mat_parameter(adj_parameter, data_ext_list[i], adj_metric)\n",
    "        adj_ext_list.append(gen_adj_mat_tensor(data_ext_list[i], adj_parameter_adaptive, adj_metric))\n",
    "    \n",
    "    return adj_ext_list\n",
    "\n",
    "def predict_external_data(model_dict, data_ext_list, adj_ext_list):\n",
    "    for m in model_dict:\n",
    "        model_dict[m].eval()\n",
    "    \n",
    "    num_view = len(data_ext_list)\n",
    "    ci_list = []\n",
    "    for i in range(num_view):\n",
    "        ci_list.append(model_dict[f\"C{i+1}\"](model_dict[f\"E{i+1}\"](data_ext_list[i], adj_ext_list[i])))\n",
    "    \n",
    "    if num_view >= 2:\n",
    "        c = model_dict[\"C\"](ci_list)\n",
    "    else:\n",
    "        c = ci_list[0]\n",
    "    \n",
    "    prob = F.softmax(c, dim=1).data.cpu().numpy()\n",
    "    return prob\n",
    "\n",
    "def calculate_metrics(true_labels, predicted_probs):\n",
    "    pred_classes = np.argmax(predicted_probs, axis=1)\n",
    "    AUROC = roc_auc_score(true_labels, predicted_probs, multi_class='ovr')\n",
    "    AUPRC = average_precision_score(true_labels, predicted_probs, average='macro')\n",
    "    accuracy = accuracy_score(true_labels, pred_classes)\n",
    "    precision = precision_score(true_labels, pred_classes, average='macro')\n",
    "    recall = recall_score(true_labels, pred_classes, average='macro')\n",
    "    f1 = f1_score(true_labels, pred_classes, average='macro')\n",
    "    return AUROC, AUPRC, accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\320\\AppData\\Local\\Temp\\ipykernel_38192\\1260644937.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(os.path.join(model_save_path, 'trained_model.model'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels length: 15\n",
      "Predicted probabilities length: 16\n",
      "True labels: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "Predicted probabilities: [[9.9970442e-01 2.9552967e-04]\n",
      " [9.9970442e-01 2.9552967e-04]\n",
      " [9.9970442e-01 2.9552967e-04]\n",
      " [9.9970442e-01 2.9552967e-04]\n",
      " [9.9970442e-01 2.9552967e-04]\n",
      " [9.1701847e-01 8.2981519e-02]\n",
      " [9.9970442e-01 2.9552967e-04]\n",
      " [8.5528094e-01 1.4471914e-01]\n",
      " [9.9932575e-01 6.7427114e-04]\n",
      " [9.9966633e-01 3.3363036e-04]\n",
      " [9.9970442e-01 2.9552967e-04]\n",
      " [9.9970442e-01 2.9552967e-04]\n",
      " [8.5443020e-01 1.4556974e-01]\n",
      " [8.5528094e-01 1.4471914e-01]\n",
      " [8.5528874e-01 1.4471120e-01]\n",
      " [9.9970442e-01 2.9553106e-04]]\n",
      "Predicted labels and probabilities saved to data(li)delete10/外部测试/external_validation_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# lilili\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    model_save_path = \"data(li)delete10\\\\训练\"  # 模型保存路径\n",
    "    external_data_folder = \"./data(li)delete10/外部测试\"  # 外部验证集路径\n",
    "    view_list = [1, 2,3]  # 根据你的数据集调整视图数量\n",
    "    adj_parameter = 10  # 根据你的模型设置调整邻接矩阵参数\n",
    "\n",
    "    # 加载模型\n",
    "    model_dict = load_model(model_save_path)\n",
    "\n",
    "    # 预处理外部验证集\n",
    "    data_ext_list, true_labels_ext = preprocess_external_data(external_data_folder, view_list)\n",
    "\n",
    "    # 生成邻接矩阵\n",
    "    adj_ext_list = generate_adj_matrix(data_ext_list, adj_parameter)\n",
    "\n",
    "    # 进行预测\n",
    "    predicted_probs = predict_external_data(model_dict, data_ext_list, adj_ext_list)\n",
    "    print(\"True labels length:\", len(true_labels_ext))\n",
    "    print(\"Predicted probabilities length:\", len(predicted_probs))\n",
    "    print(\"True labels:\", true_labels_ext)\n",
    "    print(\"Predicted probabilities:\", predicted_probs)\n",
    "    \n",
    "    # 保存预测概率和预测类别到 CSV 文件\n",
    "    pred_classes = np.argmax(predicted_probs, axis=1)  # 预测的类别\n",
    "    df_labels = pd.DataFrame(pred_classes, columns=['Predicted Label'])\n",
    "    df_prob = pd.DataFrame(predicted_probs, columns=[f'Prob_Class_{i}' for i in range(predicted_probs.shape[1])])\n",
    "    df_combined = pd.concat([df_labels, df_prob], axis=1)\n",
    "\n",
    "    # 保存到 CSV 文件\n",
    "    output_csv_path = os.path.join( 'data(li)delete10/外部测试/external_validation_predictions.csv')\n",
    "    df_combined.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Predicted labels and probabilities saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels length: 26\n",
      "Predicted probabilities length: 26\n",
      "True labels: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "Predicted probabilities: [[8.9930469e-01 1.0069536e-01]\n",
      " [8.5073966e-01 1.4926034e-01]\n",
      " [8.4834993e-01 1.5165001e-01]\n",
      " [7.6481342e-02 9.2351866e-01]\n",
      " [8.5072076e-01 1.4927919e-01]\n",
      " [8.5074055e-01 1.4925949e-01]\n",
      " [7.6587826e-02 9.2341220e-01]\n",
      " [1.9654307e-01 8.0345696e-01]\n",
      " [9.9748874e-01 2.5112869e-03]\n",
      " [9.2785216e-05 9.9990726e-01]\n",
      " [9.9748862e-01 2.5114303e-03]\n",
      " [9.9748874e-01 2.5112869e-03]\n",
      " [7.7775729e-01 2.2224267e-01]\n",
      " [8.5053712e-01 1.4946289e-01]\n",
      " [9.9244916e-01 7.5508063e-03]\n",
      " [8.2343280e-01 1.7656718e-01]\n",
      " [7.3870711e-02 9.2612934e-01]\n",
      " [7.6502360e-02 9.2349762e-01]\n",
      " [9.9748838e-01 2.5115863e-03]\n",
      " [8.4691119e-01 1.5308881e-01]\n",
      " [7.9485834e-01 2.0514166e-01]\n",
      " [8.5074079e-01 1.4925924e-01]\n",
      " [8.5065478e-01 1.4934522e-01]\n",
      " [8.4927219e-01 1.5072782e-01]\n",
      " [8.5074079e-01 1.4925919e-01]\n",
      " [8.5051465e-01 1.4948536e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\320\\AppData\\Local\\Temp\\ipykernel_38192\\1260644937.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(os.path.join(model_save_path, 'trained_model.model'))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (26, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted probabilities:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_probs)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 计算指标\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m AUROC, AUPRC, accuracy, precision, recall, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels_ext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 打印结果\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUROC: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(AUROC))\n",
      "Cell \u001b[1;32mIn[27], line 62\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[1;34m(true_labels, predicted_probs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_metrics\u001b[39m(true_labels, predicted_probs):\n\u001b[0;32m     61\u001b[0m     pred_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predicted_probs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m     AUROC \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     AUPRC \u001b[38;5;241m=\u001b[39m average_precision_score(true_labels, predicted_probs, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     64\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(true_labels, pred_classes)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\pydeseq2\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\pydeseq2\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:640\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[0;32m    639\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    649\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    650\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    653\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    654\u001b[0m     )\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\pydeseq2\\lib\\site-packages\\sklearn\\metrics\\_base.py:76\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m     79\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\pydeseq2\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:387\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m     )\n\u001b[1;32m--> 387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\pydeseq2\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\pydeseq2\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1145\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1044\u001b[0m     {\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m ):\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m \n\u001b[0;32m   1058\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1145\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\pydeseq2\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:821\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    819\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    820\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m--> 821\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m assert_all_finite(y_true)\n\u001b[0;32m    823\u001b[0m assert_all_finite(y_score)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\pydeseq2\\lib\\site-packages\\sklearn\\utils\\validation.py:1406\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1395\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1396\u001b[0m             (\n\u001b[0;32m   1397\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1402\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1403\u001b[0m         )\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1406\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1408\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (26, 2) instead."
     ]
    }
   ],
   "source": [
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    model_save_path = \"data(li)\\\\训练\"  # 模型保存路径\n",
    "    external_data_folder = \"./data(li)/外部测试\"  # 外部验证集路径\n",
    "    view_list = [1, 2,3]  # 根据你的数据集调整视图数量\n",
    "    adj_parameter = 10  # 根据你的模型设置调整邻接矩阵参数\n",
    "\n",
    "    # 加载模型\n",
    "    model_dict = load_model(model_save_path)\n",
    "\n",
    "    # 预处理外部验证集\n",
    "    data_ext_list, true_labels_ext = preprocess_external_data(external_data_folder, view_list)\n",
    "\n",
    "    # 生成邻接矩阵\n",
    "    adj_ext_list = generate_adj_matrix(data_ext_list, adj_parameter)\n",
    "\n",
    "    # 进行预测\n",
    "    predicted_probs = predict_external_data(model_dict, data_ext_list, adj_ext_list)\n",
    "    print(\"True labels length:\", len(true_labels_ext))\n",
    "    print(\"Predicted probabilities length:\", len(predicted_probs))\n",
    "    print(\"True labels:\", true_labels_ext)\n",
    "    print(\"Predicted probabilities:\", predicted_probs)\n",
    "    # 计算指标\n",
    "    AUROC, AUPRC, accuracy, precision, recall, f1 = calculate_metrics(true_labels_ext, predicted_probs)\n",
    "\n",
    "    # 打印结果\n",
    "    print(\"AUROC: {:.3f}\".format(AUROC))\n",
    "    print(\"AUPRC: {:.3f}\".format(AUPRC))\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "    print(\"Precision: {:.3f}\".format(precision))\n",
    "    print(\"Recall: {:.3f}\".format(recall))\n",
    "    print(\"F1 Score: {:.3f}\".format(f1))\n",
    "\n",
    "    # 保存预测概率和预测类别到 CSV 文件\n",
    "    pred_classes = np.argmax(predicted_probs, axis=1)  # 预测的类别\n",
    "    df_labels = pd.DataFrame(pred_classes, columns=['Predicted Label'])\n",
    "    df_prob = pd.DataFrame(predicted_probs, columns=[f'Prob_Class_{i}' for i in range(predicted_probs.shape[1])])\n",
    "    df_combined = pd.concat([df_labels, df_prob], axis=1)\n",
    "\n",
    "    # 保存到 CSV 文件\n",
    "    output_csv_path = os.path.join( 'data(li)/外部测试/external_validation_predictions.csv')\n",
    "    df_combined.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Predicted labels and probabilities saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydeseq2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
