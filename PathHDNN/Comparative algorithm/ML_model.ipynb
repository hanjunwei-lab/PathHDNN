{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt;\n",
    "from math import sqrt;\n",
    "from matplotlib import pyplot;\n",
    "import pandas as pd;\n",
    "from numpy import concatenate;\n",
    "import numpy as np;\n",
    "from sklearn.preprocessing import MinMaxScaler;\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,roc_curve,auc,matthews_corrcoef, f1_score;\n",
    "from keras.models import Sequential;\n",
    "from tensorflow.python.keras.layers.core import Dense, Dropout, Activation;\n",
    "from keras.optimizers import Adam\n",
    "from binn import BINN, Network, SuperLogger,BINNExplainer,ImportanceNetwork;\n",
    "import pandas as pd;\n",
    "from sklearn import preprocessing;\n",
    "from typing import Union;\n",
    "import torch;\n",
    "from pytorch_lightning import Trainer\n",
    "import torch.nn.functional as F\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from lifelines.utils import concordance_index\n",
    "import xgboost as xgb\n",
    "import statistics\n",
    "import shap\n",
    "def fit_data_matrix_to_network_input(data_matrix: pd.DataFrame, features, feature_column=\"Protein\") -> pd.DataFrame:\n",
    "    nr_features_in_matrix = len(data_matrix.index)\n",
    "    if len(features) > nr_features_in_matrix:\n",
    "        features_df = pd.DataFrame(features, columns=[feature_column])\n",
    "        data_matrix = data_matrix.merge(\n",
    "            features_df, how='right', on=feature_column)\n",
    "    if len(features) > 0:\n",
    "        data_matrix.set_index(feature_column, inplace=True)\n",
    "        data_matrix = data_matrix.loc[features]\n",
    "    return data_matrix\n",
    "\n",
    "\n",
    "def generate_data(data_matrix: pd.DataFrame, design_matrix: pd.DataFrame):\n",
    "    GroupOneCols = design_matrix[design_matrix['group']\n",
    "                                 == 0]['sample'].values\n",
    "    GroupTwoCols = design_matrix[design_matrix['group']\n",
    "                                 == 1]['sample'].values\n",
    "\n",
    "    df1 = data_matrix[GroupOneCols].T\n",
    "    df2 = data_matrix[GroupTwoCols].T\n",
    "    y = np.array([0 for _ in GroupOneCols] + [1 for _ in GroupTwoCols])\n",
    "    X = pd.concat([df1, df2]).fillna(0).to_numpy()\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    return X, y\n",
    "\n",
    "input_data = pd.read_csv(\"./data/SKCM144/pre-processing/brca_maf13.txt\",sep=\"\\t\");\n",
    "translation = pd.read_csv(\"./data/SKCM144/pre-processing/reactome_data13.txt\",sep=\"\\t\");\n",
    "pathways = pd.read_csv(\"./data/pathways.tsv\", sep=\"\\t\");\n",
    "network = Network(input_data=input_data,pathways=pathways,mapping=translation,input_data_column = \"Protein\",source_column = \"child\",target_column = \"parent\")\n",
    "torch.manual_seed(0)\n",
    "binn = BINN(network=network,n_layers=4,dropout=0.5,validate=True,residual=False,learning_rate=0.001)\n",
    "design_matrix = pd.read_csv('./data/SKCM144/pre-processing/sample_data13.txt',sep=\"\\t\")\n",
    "protein_matrix = fit_data_matrix_to_network_input(input_data, features=binn.features)\n",
    "X, Y = generate_data(protein_matrix, design_matrix=design_matrix)\n",
    "\n",
    "GroupOneCols = design_matrix [design_matrix ['group']== 0]['sample'].values\n",
    "GroupTwoCols = design_matrix [design_matrix ['group']== 1]['sample'].values\n",
    "a_110=GroupOneCols.tolist()+GroupTwoCols.tolist()\n",
    "#Random forest model\n",
    "model_RF = RandomForestClassifier(n_estimators=100, random_state=999)\n",
    "model_RF.fit(X, Y)\n",
    "y_pre_rf = model_RF.predict(X)\n",
    "inv_y=Y\n",
    "fpr,tpr,thersholds=roc_curve(Y, y_pre_rf )\n",
    "roc_auc= auc(fpr,tpr)\n",
    "print('Train AUC of random forest: %.3f' % roc_auc)\n",
    "y_pre_rf=y_pre_rf.ravel()\n",
    "c_index = concordance_index(inv_y, y_pre_rf)\n",
    "print('Train C-index of random forest: %.3f' % c_index)\n",
    "mcc = matthews_corrcoef(inv_y,y_pre_rf )\n",
    "print('Train MCC of random forest: %.3f' % mcc)\n",
    "F1_score = f1_score(inv_y,y_pre_rf )\n",
    "print('Train F1_score of random forest: %.3f' % F1_score)\n",
    "\n",
    "\n",
    "test_da2=pd.read_csv('./data/SKCM30/pre-processing/test_data_13.txt',sep=\"\\t\")\n",
    "test_sam2=pd.read_csv('./data/SKCM30/pre-processing/sample_test_13.txt',sep=\"\\t\")\n",
    "protein_matrix2 = fit_data_matrix_to_network_input(test_da2, features=binn.features)\n",
    "test_x,test_y = generate_data(protein_matrix2, design_matrix=test_sam2)\n",
    "y_pre_rf1 = model_RF.predict(test_x)\n",
    "fpr,tpr,thersholds=roc_curve(test_y, y_pre_rf1)\n",
    "roc_auc= auc(fpr,tpr)\n",
    "print('Test AUC of random forest: %.3f' % roc_auc)\n",
    "y_pre_rf1=y_pre_rf1.ravel()\n",
    "c_index = concordance_index(test_y, y_pre_rf1)\n",
    "print('Test C-index of random forest: %.3f' % c_index)\n",
    "mcc = matthews_corrcoef(test_y,y_pre_rf1)\n",
    "print('Test MCC of random forest: %.3f' % mcc)\n",
    "F1_score = f1_score(test_y,y_pre_rf1)\n",
    "print('Test F1_score of random forest: %.3f' % F1_score)\n",
    "\n",
    "\n",
    "\n",
    "#SVM\n",
    "model_SVM = SVC(kernel=\"rbf\",random_state=999)\n",
    "model_SVM.fit(X, Y)\n",
    "y_pre_svm = model_SVM.predict(X)\n",
    "inv_y=Y\n",
    "fpr,tpr,thersholds=roc_curve(Y, y_pre_svm)\n",
    "roc_auc= auc(fpr,tpr)\n",
    "print('Train AUC of support vector machine: %.3f' % roc_auc)\n",
    "y_pre_svm=y_pre_svm.ravel()\n",
    "c_index = concordance_index(inv_y, y_pre_svm)\n",
    "print('Train C-index of support vector machine: %.3f' % c_index)\n",
    "mcc = matthews_corrcoef(inv_y,y_pre_svm)\n",
    "print('Train MCC of support vector machine: %.3f' % mcc)\n",
    "F1_score = f1_score(inv_y,y_pre_svm )\n",
    "print('Train F1_score of support vector machine: %.3f' % F1_score)\n",
    "\n",
    "y_pre_svm1 = model_SVM.predict(test_x)\n",
    "fpr,tpr,thersholds=roc_curve(test_y, y_pre_svm1)\n",
    "roc_auc= auc(fpr,tpr)\n",
    "print('Test AUC of support vector machine: %.3f' % roc_auc)\n",
    "y_pre_svm1=y_pre_svm1.ravel()\n",
    "c_index = concordance_index(test_y, y_pre_svm1)\n",
    "print('Test C-index of support vector machine: %.3f' % c_index)\n",
    "mcc = matthews_corrcoef(test_y,y_pre_svm1)\n",
    "print('Test MCC of support vector machine: %.3f' % mcc)\n",
    "F1_score = f1_score(test_y, y_pre_svm1)\n",
    "print('Test F1_score of support vector machine: %.3f' % F1_score)\n",
    "\n",
    "#xgboost\n",
    "dtrain = xgb.DMatrix(X, label=Y)\n",
    "dtest = xgb.DMatrix(X, label=Y)\n",
    "param = {'max_depth': 6,'eta': 0.3,  'objective': 'binary:logistic',  'eval_metric': 'logloss' }\n",
    "num_round = 100\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "y_pre_xgb = bst.predict(dtest)\n",
    "fpr,tpr,thersholds=roc_curve(Y, y_pre_xgb)\n",
    "roc_auc= auc(fpr,tpr)\n",
    "print('Train AUC of XGBoost: %.3f' % roc_auc)\n",
    "y_pre_xgb=y_pre_xgb.ravel()\n",
    "c_index = concordance_index(inv_y, y_pre_xgb)\n",
    "print('Train AUC of XGBoost: %.3f' % c_index)\n",
    "median_value = statistics.median(y_pre_xgb)\n",
    "binary_classification = np.where(y_pre_xgb < median_value, 0, 1)\n",
    "mcc = matthews_corrcoef(inv_y,binary_classification )\n",
    "print('Train MCC of XGBoost: %.3f' % mcc)\n",
    "F1_score = f1_score(inv_y, binary_classification )\n",
    "print('Train F1_score of XGBoost: %.3f' % F1_score)\n",
    "\n",
    "\n",
    "dtest=xgb.DMatrix(test_x, label=test_y)\n",
    "y_pre_xgb1 = bst.predict(dtest)\n",
    "fpr,tpr,thersholds=roc_curve(test_y, y_pre_xgb1)\n",
    "roc_auc= auc(fpr,tpr)\n",
    "print('Test AUC of XGBoost: %.3f' % roc_auc)\n",
    "y_pre_xgb1=y_pre_xgb1.ravel()\n",
    "c_index = concordance_index(test_y, y_pre_xgb1)\n",
    "print('Test C-index of XGBoost: %.3f' % c_index)\n",
    "median_value = statistics.median(y_pre_xgb1)\n",
    "binary_classification = np.where(y_pre_xgb1 < median_value, 0, 1)\n",
    "mcc = matthews_corrcoef(test_y,binary_classification )\n",
    "print('Test MCC of XGBoost: %.3f' % mcc)\n",
    "F1_score = f1_score(test_y, binary_classification )\n",
    "print('Test F1_score of XGBoost: %.3f' % F1_score)\n",
    "\n",
    "\n",
    "#FNN\n",
    "train_x=X\n",
    "train_y=Y\n",
    "model = Sequential()  \n",
    "input = X.shape[1]\n",
    "model.add(Dense(128, input_shape=(input,))) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "# 使用高效的ADAM优化算法以及优化的最小均方误差损失函数\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "# 使用EarlyStopping来提前结束迭代次数，防止过拟合\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=50, verbose=2)\n",
    "# 训练\n",
    "torch.manual_seed(2)\n",
    "history = model.fit(train_x, train_y, epochs=3000, batch_size=36, verbose=2,\n",
    "                    shuffle=False, callbacks=[early_stopping])\n",
    "\n",
    "test_x=X\n",
    "test_y=Y\n",
    "# 预测\n",
    "yhat = model.predict(test_x)\n",
    "inv_yhat=yhat \n",
    "inv_y=test_y\n",
    "fpr,tpr,thersholds=roc_curve(Y, inv_yhat )\n",
    "roc_auc= auc(fpr,tpr)\n",
    "print('Train AUC of fully connected neural network: %.3f' % roc_auc)\n",
    "inv_yhat=inv_yhat.ravel()\n",
    "c_index = concordance_index(Y, inv_yhat)\n",
    "print('Train C-index of fully connected neural network: %.3f' % c_index)\n",
    "median_value = statistics.median(inv_yhat)\n",
    "binary_classification = np.where(inv_yhat < median_value, 0, 1)\n",
    "mcc = matthews_corrcoef(Y,binary_classification )\n",
    "print('Train MCC of fully connected neural network: %.3f' % mcc)\n",
    "F1_score = f1_score(Y, binary_classification )\n",
    "print('Train F1_score of fully connected neural network: %.3f' % F1_score)\n",
    "\n",
    "test_da2=pd.read_csv('./data/SKCM30/pre-processing/test_data_12.txt',sep=\"\\t\")\n",
    "test_sam2=pd.read_csv('./data/SKCM30/pre-processing/sample_test_12.txt',sep=\"\\t\")\n",
    "protein_matrix2 = fit_data_matrix_to_network_input(test_da2, features=binn.features)\n",
    "test_x,test_y = generate_data(protein_matrix2, design_matrix=test_sam2)\n",
    "yhat = model.predict(test_x)\n",
    "fpr,tpr,thersholds=roc_curve(test_y, yhat)\n",
    "roc_auc= auc(fpr,tpr)\n",
    "print('Test AUC of fully connected neural network: %.3f' % roc_auc)\n",
    "yhat=yhat.ravel()\n",
    "c_index = concordance_index(test_y, yhat)\n",
    "print('Test C-index of fully connected neural network: %.3f' % c_index)\n",
    "median_value = statistics.median(yhat)\n",
    "binary_classification = np.where(yhat < median_value, 0, 1)\n",
    "mcc = matthews_corrcoef(test_y,binary_classification )\n",
    "print('Test MCC of fully connected neural network: %.3f' % mcc)\n",
    "F1_score = f1_score(test_y, binary_classification )\n",
    "print('Test F1_score of fully connected neural network: %.3f' % F1_score)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
